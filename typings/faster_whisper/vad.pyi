"""
This type stub file was generated by pyright.
"""

import functools
import numpy as np
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

@dataclass
class VadOptions:
    """VAD options.

    Attributes:
      threshold: Speech threshold. Silero VAD outputs speech probabilities for each audio chunk,
        probabilities ABOVE this value are considered as SPEECH. It is better to tune this
        parameter for each dataset separately, but "lazy" 0.5 is pretty good for most datasets.
      neg_threshold: Silence threshold for determining the end of speech. If a probability is lower
        than neg_threshold, it is always considered silence. Values higher than neg_threshold
        are only considered speech if the previous sample was classified as speech; otherwise,
        they are treated as silence. This parameter helps refine the detection of speech
         transitions, ensuring smoother segment boundaries.
      min_speech_duration_ms: Final speech chunks shorter min_speech_duration_ms are thrown out.
      max_speech_duration_s: Maximum duration of speech chunks in seconds. Chunks longer
        than max_speech_duration_s will be split at the timestamp of the last silence that
        lasts more than 100ms (if any), to prevent aggressive cutting. Otherwise, they will be
        split aggressively just before max_speech_duration_s.
      min_silence_duration_ms: In the end of each speech chunk wait for min_silence_duration_ms
        before separating it
      speech_pad_ms: Final speech chunks are padded by speech_pad_ms each side
    """
    threshold: float = ...
    neg_threshold: float = ...
    min_speech_duration_ms: int = ...
    max_speech_duration_s: float = ...
    min_silence_duration_ms: int = ...
    speech_pad_ms: int = ...


def get_speech_timestamps(audio: np.ndarray, vad_options: Optional[VadOptions] = ..., sampling_rate: int = ..., **kwargs) -> List[dict]:
    """This method is used for splitting long audios into speech chunks using silero VAD.

    Args:
      audio: One dimensional float array.
      vad_options: Options for VAD processing.
      sampling rate: Sampling rate of the audio.
      kwargs: VAD options passed as keyword arguments for backward compatibility.

    Returns:
      List of dicts containing begin and end samples of each speech chunk.
    """
    ...

def collect_chunks(audio: np.ndarray, chunks: List[dict], sampling_rate: int = ..., max_duration: float = ...) -> Tuple[List[np.ndarray], List[Dict[str, float]]]:
    """This function merges the chunks of audio into chunks of max_duration (s) length."""
    ...

class SpeechTimestampsMap:
    """Helper class to restore original speech timestamps."""
    def __init__(self, chunks: List[dict], sampling_rate: int, time_precision: int = ...) -> None:
        ...
    
    def get_original_time(self, time: float, chunk_index: Optional[int] = ..., is_end: bool = ...) -> float:
        ...
    
    def get_chunk_index(self, time: float, is_end: bool = ...) -> int:
        ...
    


@functools.lru_cache
def get_vad_model(): # -> SileroVADModel:
    """Returns the VAD model instance."""
    ...

class SileroVADModel:
    def __init__(self, encoder_path, decoder_path) -> None:
        ...
    
    def __call__(self, audio: np.ndarray, num_samples: int = ..., context_size_samples: int = ...): # -> ndarray[_AnyShape, dtype[Any]]:
        ...
    


